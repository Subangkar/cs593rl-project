% BibTeX Bibliography File for FigRL Paper
% RL-Guided Typographic Attacks on Vision-Language Models

@inproceedings{liu2024llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023},
  url={https://arxiv.org/abs/2304.08485}
}

@inproceedings{cheng2024unveiling,
  title={Unveiling typographic deceptions: Insights of the typographic vulnerability in large vision-language models},
  author={Cheng, Hao and Xiao, Erjia and Gu, Junda and Yang, Le and Duan, Jiaqi and Zhang, Jinhao and Cao, Jiancheng and Xu, Kaidi and Xu, Renjing},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={179--196},
  year={2024},
  organization={Springer},
  url={https://arxiv.org/abs/2402.19150}
}

@inproceedings{gong2024figstep,
  title={FigStep: Jailbreaking large vision-language models via typographic visual prompts},
  author={Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={22},
  pages={23951--23959},
  year={2025},
  url={https://arxiv.org/abs/2311.05608}
}

@inproceedings{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
  url={https://arxiv.org/abs/2203.02155}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022},
  url={https://arxiv.org/abs/2212.08073}
}

@inproceedings{wei2023jailbroken,
  title={Jailbroken: How does LLM safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023},
  url={https://arxiv.org/abs/2307.02483}
}

@article{zhang2025fc,
  title={FC-Attack: Jailbreaking large vision-language models via auto-generated flowcharts},
  author={Zhang, Zichen and Sun, Zhong and Zhang, Zheng and Guo, Jieyu and He, Xin},
  journal={arXiv preprint arXiv:2502.21059},
  year={2025}
}

@inproceedings{cao2025scenetap,
  title={SceneTap: Scene-coherent typographic adversarial planner against vision-language models in real-world environments},
  author={Cao, Yue and Xing, Yunshi and Zhang, Jiaxin and Lin, Dongxia and Zhang, Tianyi and Tsang, Ivor and Ong, Yew-Soon and Guo, Qing},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={25050--25059},
  year={2025}
}

@article{li2025agenttypo,
  title={AgentTypo: Adaptive typographic prompt injection attacks against black-box multimodal agents},
  author={Li, Yiran and Cao, Yutao and Wang, Dongxia and Xiao, Bin},
  journal={arXiv preprint arXiv:2510.04257},
  year={2025}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023},
  url={https://arxiv.org/abs/2307.15043}
}

@article{liu2023autodan,
  title={AutoDAN: Automatic and interpretable adversarial attacks on large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.15140},
  year={2023},
  url={https://arxiv.org/abs/2310.15140}
}

@inproceedings{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2014},
  url={https://arxiv.org/abs/1312.6199}
}

@inproceedings{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2015},
  url={https://arxiv.org/abs/1412.6572}
}

@inproceedings{wallace2019universal,
  title={Universal adversarial triggers for attacking and analyzing NLP},
  author={Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP)},
  pages={2153--2162},
  year={2019},
  url={https://arxiv.org/abs/1908.07125}
}

@inproceedings{ebrahimi2018hotflip,
  title={HotFlip: White-box adversarial examples for text classification},
  author={Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={31--36},
  year={2018},
  url={https://arxiv.org/abs/1712.06751}
}

@inproceedings{belinkov2017synthetic,
  title={Synthetic and natural noise both break neural machine translation},
  author={Belinkov, Yonatan and Bisk, Yonatan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018},
  url={https://arxiv.org/abs/1711.02173}
}

@inproceedings{ranzato2015sequence,
  title={Sequence level training with recurrent neural networks},
  author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016},
  url={https://arxiv.org/abs/1511.06732}
}

@inproceedings{li2016deep,
  title={Deep reinforcement learning for dialogue generation},
  author={Li, Jiwei and Monroe, Will and Ritter, Alan and Jurafsky, Dan and Galley, Michel and Gao, Jianfeng},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1192--1202},
  year={2016},
  url={https://arxiv.org/abs/1606.01541}
}

@inproceedings{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018},
  url={https://arxiv.org/abs/1705.04304}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019},
  url={https://arxiv.org/abs/1909.08593}
}

@inproceedings{chen2024llm,
  title={When LLM meets DRL: Advancing jailbreaking efficiency via DRL-guided search},
  author={Chen, Xuan and Nie, Yuzhou and Guo, Wenbo and Zhang, Xiangyu},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={37},
  pages={26814--26845},
  year={2024},
  url={https://arxiv.org/abs/2406.08705}
}

@inproceedings{yang2024sneakyprompt,
  title={SneakyPrompt: Jailbreaking text-to-image generative models},
  author={Yang, Yuchen and Hui, Bo and Yuan, Haolin and Gong, Neil and Cao, Yinzhi},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)},
  pages={897--912},
  year={2024},
  organization={IEEE},
  url={https://arxiv.org/abs/2305.12082}
}

@inproceedings{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={3419--3448},
  year={2022},
  url={https://arxiv.org/abs/2202.03286}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022},
  url={https://arxiv.org/abs/2209.07858}
}

@inproceedings{perez2022discovering,
  title={Discovering language model behaviors with model-written evaluations},
  author={Perez, Ethan and Ringer, Sam and Lukošiūtė, Kamilė and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13387--13434},
  year={2023},
  url={https://arxiv.org/abs/2212.09251}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017},
  url={https://arxiv.org/abs/1707.06347}
}

@inproceedings{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016},
  url={https://arxiv.org/abs/1506.02438}
}
